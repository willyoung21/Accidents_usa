{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Establishing Database Connection\n",
    "\n",
    "In this section, we import the necessary libraries for the analysis and set up the database connection by appending the path to the project directory and importing the custom function establecer_conexion from the src.db_conexion module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion exitosa a la base de datos\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from src.db_conexion import establecer_conexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to define some variables, which will make it possible for us to extract the data from the database that we have, in this case, the variable conn, what it does is extract the database. With the cursor variable, what allows us to go through the data in our database, and finally, we create a query that allows us to create an SQL function to be able to extract the entire table, and then save it in a DataFrame and be able to do everything the possible analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we establish a connection to the database using the establecer_conexion function and execute an SQL query to fetch data from the us_accidents table. The retrieved data is then loaded into a pandas DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion exitosa a la base de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7837/439132754.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7cb33367fd90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/willyb/Documentos/Accidents_usa/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Establish a connection and create a cursor\n",
    "conn, cursor = establecer_conexion()  # Function to establish the database connection\n",
    "\n",
    "# SQL query to select all data from the 'us_accidents' table\n",
    "query = \"SELECT * FROM us_accidents\"\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what we simply do is verify the database, to see if the connection with the database was made correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Automatically adjust display width to fit the content\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display the first 20 rows in a tabular format\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure pandas to display more rows and columns\n",
    "pd.set_option('display.max_rows', 100)  # Show up to 100 rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns without truncation\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to fit the content\n",
    "\n",
    "# Display the first 20 rows in a tabular format\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we proceed with all the cleaning.\n",
    "\n",
    "1. First of all, we chose the columns that we saw pertinent to eliminate, which we eliminated because they did not give us relevant information, or had most of their data null, or simply there were more columns with the same information with which we could guide ourselves.\n",
    "\n",
    "2. For meteorological variables, such as temperature or wind speed, what we did was a numerical estimate taking into account the existing values ​​in this column, then we could use the mode, the mean, the most frequent value or the closest value\n",
    "\n",
    "3. Then we proceed to eliminate rows with null values, which makes it even easier for us to read the existing data in the column, and then proceed to count both the number of null values ​​and the number of empty values, in order to do so. finally being able to have a cleaner and more readable database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "columns_to_drop = ['id', 'source', 'country', 'description', 'end_lat', 'end_lng', \n",
    "                   'civil_twilight', 'nautical_twilight', 'astronomical_twilight']\n",
    "\n",
    "# Drop the specified columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Impute missing values in numerical columns with the mean\n",
    "df_cleaned['temperature_f'].fillna(df_cleaned['temperature_f'].mean(), inplace=True)\n",
    "\n",
    "# Impute missing values in categorical columns with the mode (most frequent value)\n",
    "df_cleaned['weather_condition'].fillna(df_cleaned['weather_condition'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute missing values in multiple numerical columns with the mean\n",
    "num_cols = ['wind_chill_f', 'humidity_percent', 'pressure_in', 'visibility_mi', 'wind_speed_mph', 'precipitation_in']\n",
    "df_cleaned[num_cols] = df_cleaned[num_cols].apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "# Impute the 'wind_direction' column with the most frequent value (mode)\n",
    "df_cleaned['wind_direction'] = df_cleaned['wind_direction'].fillna(df_cleaned['wind_direction'].mode()[0])\n",
    "\n",
    "# Impute 'weather_timestamp' with the previous value (forward fill) for missing timestamps\n",
    "df_cleaned['weather_timestamp'] = df_cleaned['weather_timestamp'].fillna(method='ffill')\n",
    "\n",
    "# Remove rows containing any remaining missing values\n",
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "# Count missing (NaN) values in each column\n",
    "nan_counts = df_cleaned.isna().sum()\n",
    "\n",
    "# Count empty strings ('') in each column\n",
    "empty_counts = (df_cleaned == '').sum()\n",
    "\n",
    "# Combine the counts into a single DataFrame for better visualization\n",
    "null_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Empty String Count': empty_counts,\n",
    "    'Total Missing': nan_counts + empty_counts\n",
    "})\n",
    "\n",
    "# Display the summary of missing values\n",
    "print(null_summary)\n",
    "\n",
    "# Configure pandas to display more rows and columns if necessary\n",
    "pd.set_option('display.max_rows', 10000)  # Show up to 10,000 rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "\n",
    "# Show the first 100 rows of the cleaned DataFrame in a tabular format\n",
    "df_cleaned.head(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
