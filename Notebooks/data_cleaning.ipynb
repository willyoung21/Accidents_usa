{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is install all the libraries that we are going to need to be able to make the connection to the database, extract that data, and be able to clean it, in addition to importing the 'establish_connection' function which is what It allows us, as its name says, to make the connection with our database located in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from db_conexion import establecer_conexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to define some variables, which will make it possible for us to extract the data from the database that we have, in this case, the variable conn, what it does is extract the database. With the cursor variable, what allows us to go through the data in our database, and finally, we create a query that allows us to create an SQL function to be able to extract the entire table, and then save it in a DataFrame and be able to do everything the possible analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion exitosa a la base de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_14760\\4066787522.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Establish a connection and create a cursor\n",
    "conn, cursor = establecer_conexion()  # Function to establish the database connection\n",
    "\n",
    "# SQL query to select all data from the 'us_accidents' table\n",
    "query = \"SELECT * FROM us_accidents\"\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what we simply do is verify the database, to see if the connection with the database was made correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure pandas to display more rows and columns\n",
    "pd.set_option('display.max_rows', 100)  # Show up to 100 rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns without truncation\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to fit the content\n",
    "\n",
    "# Display the first 20 rows in a tabular format\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we proceed with all the cleaning.\n",
    "\n",
    "1. First of all, we chose the columns that we saw pertinent to eliminate, which we eliminated because they did not give us relevant information, or had most of their data null, or simply there were more columns with the same information with which we could guide ourselves.\n",
    "\n",
    "2. For meteorological variables, such as temperature or wind speed, what we did was a numerical estimate taking into account the existing values ​​in this column, then we could use the mode, the mean, the most frequent value or the closest value\n",
    "\n",
    "3. Then we proceed to eliminate rows with null values, which makes it even easier for us to read the existing data in the column, and then proceed to count both the number of null values ​​and the number of empty values, in order to do so. finally being able to have a cleaner and more readable database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "columns_to_drop = ['id', 'source', 'country', 'description', 'end_lat', 'end_lng', \n",
    "                   'civil_twilight', 'nautical_twilight', 'astronomical_twilight']\n",
    "\n",
    "# Drop the specified columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Impute missing values in numerical columns with the mean\n",
    "df_cleaned['temperature_f'].fillna(df_cleaned['temperature_f'].mean(), inplace=True)\n",
    "\n",
    "# Impute missing values in categorical columns with the mode (most frequent value)\n",
    "df_cleaned['weather_condition'].fillna(df_cleaned['weather_condition'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute missing values in multiple numerical columns with the mean\n",
    "num_cols = ['wind_chill_f', 'humidity_percent', 'pressure_in', 'visibility_mi', 'wind_speed_mph', 'precipitation_in']\n",
    "df_cleaned[num_cols] = df_cleaned[num_cols].apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "# Impute the 'wind_direction' column with the most frequent value (mode)\n",
    "df_cleaned['wind_direction'] = df_cleaned['wind_direction'].fillna(df_cleaned['wind_direction'].mode()[0])\n",
    "\n",
    "# Impute 'weather_timestamp' with the previous value (forward fill) for missing timestamps\n",
    "df_cleaned['weather_timestamp'] = df_cleaned['weather_timestamp'].fillna(method='ffill')\n",
    "\n",
    "# Remove rows containing any remaining missing values\n",
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "# Count missing (NaN) values in each column\n",
    "nan_counts = df_cleaned.isna().sum()\n",
    "\n",
    "# Count empty strings ('') in each column\n",
    "empty_counts = (df_cleaned == '').sum()\n",
    "\n",
    "# Combine the counts into a single DataFrame for better visualization\n",
    "null_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Empty String Count': empty_counts,\n",
    "    'Total Missing': nan_counts + empty_counts\n",
    "})\n",
    "\n",
    "# Display the summary of missing values\n",
    "print(null_summary)\n",
    "\n",
    "# Configure pandas to display more rows and columns if necessary\n",
    "pd.set_option('display.max_rows', 10000)  # Show up to 10,000 rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "\n",
    "# Show the first 100 rows of the cleaned DataFrame in a tabular format\n",
    "df_cleaned.head(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
