{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is install all the libraries that we are going to need to be able to make the connection to the database, extract that data, and be able to clean it, in addition to importing the 'establish_connection' function which is what It allows us, as its name says, to make the connection with our database located in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from db_conexion import establecer_conexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to define some variables, which will make it possible for us to extract the data from the database that we have, in this case, the variable conn, what it does is extract the database. With the cursor variable, what allows us to go through the data in our database, and finally, we create a query that allows us to create an SQL function to be able to extract the entire table, and then save it in a DataFrame and be able to do everything the possible analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion exitosa a la base de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_14760\\4066787522.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "conn, cursor = establecer_conexion()\n",
    "\n",
    "# Consulta SQL para seleccionar los datos\n",
    "query = \"SELECT * FROM us_accidents\"\n",
    "\n",
    "# Leer los datos en un DataFrame de pandas\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what we simply do is verify the database, to see if the connection with the database was made correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configurar pandas para mostrar más filas y columnas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "\n",
    "# Mostrar las primeras 20 filas en formato tabular\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we proceed with all the cleaning.\n",
    "\n",
    "1. First of all, we chose the columns that we saw pertinent to eliminate, which we eliminated because they did not give us relevant information, or had most of their data null, or simply there were more columns with the same information with which we could guide ourselves.\n",
    "\n",
    "2. For meteorological variables, such as temperature or wind speed, what we did was a numerical estimate taking into account the existing values ​​in this column, then we could use the mode, the mean, the most frequent value or the closest value\n",
    "\n",
    "3. Then we proceed to eliminate rows with null values, which makes it even easier for us to read the existing data in the column, and then proceed to count both the number of null values ​​and the number of empty values, in order to do so. finally being able to have a cleaner and more readable database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Columnas a eliminar\n",
    "columns_to_drop = ['id', 'source', 'country', 'description', 'end_lat', 'end_lng', \n",
    "                'civil_twilight', 'nautical_twilight', 'astronomical_twilight']\n",
    "\n",
    "# Eliminación de las columnas\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Imputar valores nulos en columnas numéricas con la media\n",
    "df_cleaned['temperature_f'].fillna(df_cleaned['temperature_f'].mean(), inplace=True)\n",
    "\n",
    "# Imputar valores nulos en columnas categóricas con la moda\n",
    "df_cleaned['weather_condition'].fillna(df_cleaned['weather_condition'].mode()[0], inplace=True)\n",
    "\n",
    "# Imputar columnas numéricas con la media\n",
    "num_cols = ['wind_chill_f', 'humidity_percent', 'pressure_in', 'visibility_mi', 'wind_speed_mph', 'precipitation_in']\n",
    "df_cleaned[num_cols] = df_cleaned[num_cols].apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "# Imputar columna categórica con el valor más frecuente\n",
    "df_cleaned['wind_direction'] = df_cleaned['wind_direction'].fillna(df_cleaned['wind_direction'].mode()[0])\n",
    "\n",
    "# Imputar Weather_Timestamp con el valor más cercano (por tiempo)\n",
    "df_cleaned['weather_timestamp'] = df_cleaned['weather_timestamp'].fillna(method='ffill')\n",
    "\n",
    "# Eliminar filas que contienen valores nulos\n",
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "# Contar valores nulos (NaN) en cada columna\n",
    "nan_counts = df_cleaned.isna().sum()\n",
    "\n",
    "# Contar valores vacíos ('') en cada columna\n",
    "empty_counts = (df_cleaned == '').sum()\n",
    "\n",
    "# Combinar los conteos en un solo DataFrame para visualizar mejor\n",
    "null_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Empty String Count': empty_counts,\n",
    "    'Total Missing': nan_counts + empty_counts\n",
    "})\n",
    "\n",
    "# Mostrar el resumen\n",
    "print(null_summary)\n",
    "\n",
    "# Configuración para mostrar más filas y columnas si es necesario\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Mostrar el DataFrame en formato tabular\n",
    "df_cleaned.head(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
